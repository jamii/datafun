% TyDe wants sigplan & ``Extended abstract'' clearly in the title.
% HOPE doesn't seem to care.
% FHPC wants acmart, doesn't specify sigplan.

% https://icfp18.sigplan.org/track/tyde-2018#Call-for-Contributions
% https://icfp18.sigplan.org/track/hope-2018-papers#Call-for-Presentations
% https://icfp18.sigplan.org/track/FHPC-2018-papers#FHPC-2018-Call-for-Papers

\documentclass[sigplan,screen,review,timestamp,dvipsnames]{acmart}
%\usepackage[scaled=1.023]{cochineal}


%% ---- Packages ----
\usepackage{amsmath,latexsym,stmaryrd}
\usepackage[nameinlink]{cleveref}
\usepackage{mathtools}          % \dblcolon
\usepackage{anyfontsize}
\usepackage{lipsum}
\usepackage{listings}
\lstset{language=prolog, columns=fullflexible,
  basicstyle=\ttfamily, commentstyle=\color{Green}}

%% %% Avoid ``too many math alphabets'' error.
%% \newcommand\hmmax{0}
%% \newcommand\bmmax{0}
%% \usepackage{bm}


%% ---- Top matter ----
\title{Finding fixed points faster}
% The derivative of a fixed point is the fixed point of its derivative
% Finding fixed points faster
% Finding fixed points faster by differentiation
% Deriving incremental recursive queries
\author{Michael Arntzenius}
\affiliation{University of Birmingham}
\email{daekharel@gmail.com}
\setcopyright{none}
\settopmatter{printacmref=false}

%% TODO
%\terms{blah}
%\keywords{blah}


%% ---- Commands ----
\newcommand{\todo}[1]{{\color{ACMPurple}#1}}
\newcommand{\hilited}{\color{Cyan}}

\renewcommand{\d}{\delta}
\newcommand{\dzero}{\mathbf{0}~} % todo: mathbold, or \mb or something
\newcommand{\fn}{\lambda}
\newcommand{\binder}{.~}
\newcommand{\bind}[1]{#1\binder}
\newcommand{\fnof}[1]{\fn\bind{#1}}

\newcommand{\kw}[1]{\textsf{\bfseries#1}}
\newcommand{\ebiglub}[1]{\bigcup(#1)~}
\newcommand{\elet}[1]{\kw{let}~#1~\kw{in}~}
\newcommand{\subst}[1]{\,[#1]}
\newcommand{\efix}{\kw{fix}~}
\newcommand{\tlv}[1]{\textrm{#1}}
\newcommand{\var}[1]{\mathit{#1}}
\newcommand{\dee}[1]{\var{d#1}}


\begin{document}

%% \begin{abstract}
%%   Logic programming has a powerful appeal: declare what counts as a solution, and
%%   let the computer find it! Unfortunately, traditional logic programming systems
%%   like Prolog have trouble going truly \emph{higher-order} in the way functional
%%   programmers are used to. Seeking to have their cake and eat it, too, functional
%%   programmers have learned to emulate logic programming using the effect of
%%   \emph{nondeterminism}, usually implemented as backtracking.

%%   However, backtracking search is often inefficient; logic programmers have
%%   explored other useful strategies. Datalog~\citep{datalog} takes an extreme
%%   approach, allowing only predicates with finite extent. This allows bottom-up
%%   evaluation, which easily handles queries (such as transitive closure) which are
%%   difficult or inefficient to implement in Prolog.

%%   Recently, Datafun~\cite{datafun} has shown that higher-order functional programs
%%   can emulate Datalog using a \emph{bottom-up nondeterminism effect} (a
%%   \emph{finite set monad}) combined with \emph{monotone fixed points}. In the
%%   present work, we sketch a translation of a classic Datalog optimisation,
%%   semina\"ive evaluation, to Datafun.
%% \end{abstract}

% \begin{abstract} blah \end{abstract}
\maketitle

\section{Introduction}
Logic programming has a powerful appeal: declare what counts as a solution, and
let the computer find it! Unfortunately, traditional logic programming systems
like Prolog have trouble going truly \emph{higher-order} in the way functional
programmers are used to. Seeking to have their cake and eat it, too, functional
programmers have learned to emulate logic programming using the effect of
\emph{nondeterminism}, usually implemented as backtracking.

However, backtracking search is often inefficient; logic programmers have
explored other useful strategies. Datalog~\citep{datalog} takes an extreme
approach, allowing only predicates with finite extent. This allows bottom-up
evaluation, which easily handles queries (such as transitive closure) which are
difficult or inefficient to implement in Prolog.

Recently, Datafun~\cite{datafun} has shown that higher-order functional programs
can emulate Datalog using a \emph{bottom-up nondeterminism effect} (a
\emph{finite set monad}) combined with \emph{monotone fixed points}. In the
present work, we sketch a translation of a classic Datalog optimisation,
semina\"ive evaluation, to Datafun.


\section{Datalog and Datafun}

This classic Datalog program computes the transitive closure of an \texttt{edge}
relation:
%
\begin{lstlisting}
path(X,Y) :- edge(X,Y).
path(X,Z) :- edge(X,Y), path(Y,Z).
\end{lstlisting}

\todo{TODO: How do I quickly introduce Datafun?}

\newcommand{\bnfeq}{\dblcolon=}
\newcommand{\bnfcont}{}
\newcommand{\pipe}{~|~}
\newcommand{\x}{\times}

\newcommand{\mto}{\overset{+}{\to}}
\newcommand{\tset}[1]{\{#1\}}
\newcommand{\eset}[1]{\{#1\}}

\begin{figure}
  \[
  \begin{array}{rcl}
    A,B &\bnfeq& \tset{A} \pipe A \to B \pipe A \mto B
    \\
    e &\bnfeq& \fnof{x} e \pipe e_1\:e_2 \pipe \eset{\vec{e}} \pipe e_1 \cup e_2
    \pipe \bigcup(x \in e_1)~ e_2
  \end{array}
  \]\vspace{-1em}
  \caption{A fragment of Datafun}
  \label{fig:datafun}
\end{figure}

\section{Semina\"ive evaluation}

\section{Change structures}

\todo{TODO: describe our version of change structures and derivatives}


\begin{figure}
  \[\begin{array}{rcl}
    \d x &=& dx\\
    \d(\fnof x e) &=& \fnof x \fnof{\dee x} \d{e}\\
    \d(e_1~e_2) &=& \d{e_1}~e_2~\d{e_2}\\
    \d(e_1 \cup e_2) &=& \d{e_1} \cup \d{e_2}\\
    \d{\{e\}} &=& \emptyset\\
    \d(\ebiglub{x \in e_1} e_2)
    &=& \ebiglub{x \in \d{e_1}} e_2\\
    &\cup& \ebiglub{x \in e_1 \cup \d{e_1}}
    \elet{\dee x = \dzero x}
    \d{e_2}
    %\subst{dx \mapsto \dzero x}
    \\
    \d(\efix f) &=& \efix (\d\!f~(\efix f))
  \end{array}\]
  \caption{Derivatives for a fragment of Datafun}
  \label{fig:derivatives}
\end{figure}

\begin{figure}
  \[
  \begin{array}{rcl}
  \efix f &=& \tlv{na\"ive}_f \,\emptyset \,(f\, \emptyset)\\
  \tlv{na\"ive}_f \,x \,\var{next}
  &=& \kw{if}~ x = \var{next} ~\kw{then}~ x ~\kw{else}\\
  && \tlv{na\"ive}_f \,\var{next} \,(f \,\var{next})

  \vspace{1em}\\

  \efix f &=& \tlv{semina\"ive}_f \,\emptyset \,(f\, \emptyset)\\
  \tlv{semina\"ive}_f \,x \,\dee x
  &=& \kw{if}~ \dee x \subseteq x ~\kw{then}~ x ~\kw{else}\\
  && \tlv{semina\"ive}_f \,(x \cup \dee x) \,(\d\!f \,x \,\dee x)
  %% \tlv{semina\"ive-fix} \:\dee f \:x \:\var{new}
  %% &=& \elet{\var{toadd} = \var{df} \:x \:\var{new}}\\
  %% && \kw{if}~ \var{to-add} \subseteq x

  %% fix f x next =
  %%   if next = x then x
  %%   else fix f next (f next)
  %%
  %% fix-fast df x dx =
  %%   if dx ⊆ x then x else
  %%   fix-fast df (x ∪ dx) (df x dx)
  \end{array}
  \]
  \caption{Na\"ive and semina\"ive fixed point computation}
  \label{fig:defining-fix}
\end{figure}

Observe that $\d(\efix f)$ must be a fixed point of $\d\!f\;(\efix f)$:
%% We discovered the definition of $\d(\efix f)$ in \cref{fig:derivatives} by
%% observing that, if it exists, $\d(\efix f)$ must be a fixed point of $\d\!f\;
%% (\efix f)$:
%
\begin{align*}
  {\hilited \d(\efix f)}
  &= \d(f\: (\efix f))
  & \text{expand fixed point}\\
  &= \d\!f\; (\efix f)\; {\hilited \d(\efix f)}
  & \text{rule for}~\delta(e_1\;e_2)
\end{align*}
%
Which suggests the following motto:
\begin{center}
  \large \scshape
  the derivative of a fixed point\\
  is the fixed point of its derivative.
\end{center}
%
This is so beautiful it must be true. Nevertheless, we have proven the definition of $\delta(\efix f)$ in \cref{fig:derivatives} correct~\citep{fixderiv}.

%{\color{ACMGreen} \lipsum}


%% TODO: code for naive-fix and seminaive-fix


%% Bibliography
\bibliographystyle{abbrvnat}
\bibliography{datafun}

\end{document}
